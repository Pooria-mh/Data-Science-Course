{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3f53fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-02 19:29:32,411 INFO Producing 20000 historical events...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "localhost:9092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mehrad\\AppData\\Local\\Temp\\ipykernel_21776\\3363734712.py:105: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  now = datetime.datetime.utcnow()\n",
      "2025-05-02 19:29:33,810 INFO Historical events production completed.\n",
      "2025-05-02 19:29:33,811 INFO Starting continuous event production...\n",
      "C:\\Users\\mehrad\\AppData\\Local\\Temp\\ipykernel_21776\\3363734712.py:122: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  current_hour = datetime.datetime.utcnow().hour\n",
      "C:\\Users\\mehrad\\AppData\\Local\\Temp\\ipykernel_21776\\3363734712.py:44: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  timestamp_override if timestamp_override else datetime.datetime.utcnow()\n",
      "2025-05-02 20:18:36,986 ERROR Message delivery failed: KafkaError{code=_MSG_TIMED_OUT,val=-192,str=\"Local: Message timed out\"}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "import uuid\n",
    "import json\n",
    "import datetime\n",
    "import logging\n",
    "from datetime import timedelta\n",
    "from confluent_kafka import Producer, Consumer, TopicPartition\n",
    "from confluent_kafka.admin import AdminClient\n",
    "\n",
    "log_level_str = os.getenv(\"LOG_LEVEL\", \"INFO\").upper()\n",
    "logging.basicConfig(\n",
    "    level=getattr(logging, log_level_str, logging.INFO),\n",
    "    format=\"%(asctime)s %(levelname)s %(message)s\",\n",
    ")\n",
    "\n",
    "MERCHANT_CATEGORIES = [\n",
    "    \"retail\",\n",
    "    \"food_service\",\n",
    "    \"entertainment\",\n",
    "    \"transportation\",\n",
    "    \"government\",\n",
    "]\n",
    "PAYMENT_METHODS = [\"online\", \"pos\", \"mobile\", \"nfc\"]\n",
    "COMMISSION_TYPES = [\"flat\", \"progressive\", \"tiered\"]\n",
    "CUSTOMER_TYPES = [\"individual\", \"CIP\", \"business\"]\n",
    "FAILURE_REASONS = [\"cancelled\", \"insufficient_funds\", \"system_error\", \"fraud_prevented\"]\n",
    "DEVICE_INFO_LIBRARY = [\n",
    "    {\"os\": \"Android\", \"app_version\": \"2.4.1\", \"device_model\": \"Samsung Galaxy S25\"},\n",
    "    {\"os\": \"iOS\", \"app_version\": \"3.1.0\", \"device_model\": \"iPhone 15\"},\n",
    "    {\"os\": \"Android\", \"app_version\": \"1.9.5\", \"device_model\": \"Google Pixel 6\"},\n",
    "]\n",
    "\n",
    "\n",
    "def generate_random_datetime(start, end):\n",
    "    delta = end - start\n",
    "    random_seconds = random.uniform(0, delta.total_seconds())\n",
    "    return start + timedelta(seconds=random_seconds)\n",
    "\n",
    "\n",
    "def generate_transaction_event(is_historical=False, timestamp_override=None):\n",
    "    event_time = (\n",
    "        timestamp_override if timestamp_override else datetime.datetime.utcnow()\n",
    "    )\n",
    "    transaction_id = str(uuid.uuid4())\n",
    "    customer_id = f\"cust_{random.randint(1, customer_count)}\"\n",
    "    merchant_id = f\"merch_{random.randint(1, merchant_count)}\"\n",
    "    merchant_category = random.choice(MERCHANT_CATEGORIES)\n",
    "    payment_method = random.choice(PAYMENT_METHODS)\n",
    "    amount = random.randint(50000, 2000000)\n",
    "    base = merchant_bases[merchant_id]\n",
    "    location = {\n",
    "           \"lat\": base[\"lat\"] + random.uniform(-0.005, 0.005),\n",
    "           \"lng\": base[\"lng\"] + random.uniform(-0.005, 0.005),\n",
    "    }\n",
    "\n",
    "    device_info = (\n",
    "        random.choice(DEVICE_INFO_LIBRARY)\n",
    "        if payment_method in [\"online\", \"mobile\"]\n",
    "        else {}\n",
    "    )\n",
    "    if random.random() < declined_rate:\n",
    "        status = \"declined\"\n",
    "        failure_reason = random.choice(FAILURE_REASONS)\n",
    "    else:\n",
    "        status = \"approved\"\n",
    "        failure_reason = None\n",
    "    risk_level = 5 if random.random() < fraud_rate else random.randint(1, 3)\n",
    "    commission_type = random.choice(COMMISSION_TYPES)\n",
    "    commission_amount = int(amount * 0.02)\n",
    "    vat_amount = int(amount * 0.09)\n",
    "    total_amount = amount + vat_amount + commission_amount\n",
    "    event = {\n",
    "        \"transaction_id\": transaction_id,\n",
    "        \"timestamp\": event_time.isoformat() + \"Z\",\n",
    "        \"customer_id\": customer_id,\n",
    "        \"merchant_id\": merchant_id,\n",
    "        \"merchant_category\": merchant_category,\n",
    "        \"payment_method\": payment_method,\n",
    "        \"amount\": amount,\n",
    "        \"location\": location,\n",
    "        \"device_info\": device_info,\n",
    "        \"status\": status,\n",
    "        \"commission_type\": commission_type,\n",
    "        \"commission_amount\": commission_amount,\n",
    "        \"vat_amount\": vat_amount,\n",
    "        \"total_amount\": total_amount,\n",
    "        \"customer_type\": random.choice(CUSTOMER_TYPES),\n",
    "        \"risk_level\": risk_level,\n",
    "        \"failure_reason\": failure_reason,\n",
    "    }\n",
    "    return event\n",
    "\n",
    "\n",
    "def delivery_report(err, msg):\n",
    "    if err is not None:\n",
    "        logging.error(f\"Message delivery failed: {err}\")\n",
    "    else:\n",
    "        logging.debug(f\"Delivered to {msg.topic()} [{msg.partition()}]\")\n",
    "\n",
    "\n",
    "def produce_historical_events(producer, topic, count=20000):\n",
    "    logging.info(f\"Producing {count} historical events...\")\n",
    "    now = datetime.datetime.utcnow()\n",
    "    start_time = now - timedelta(days=7)\n",
    "    for _ in range(count):\n",
    "        event_time = generate_random_datetime(start_time, now)\n",
    "        event = generate_transaction_event(timestamp_override=event_time)\n",
    "        producer.produce(\n",
    "            topic,\n",
    "            key=event[\"customer_id\"],\n",
    "            value=json.dumps(event),\n",
    "            callback=delivery_report,\n",
    "        )\n",
    "    producer.flush()\n",
    "    logging.info(\"Historical events production completed.\")\n",
    "\n",
    "\n",
    "def continuous_event_production(producer, topic, base_rate):\n",
    "    while True:\n",
    "        current_hour = datetime.datetime.utcnow().hour\n",
    "        multiplier = peak_factor if 9 <= current_hour < 18 else 1.0\n",
    "        effective_rate = base_rate * multiplier\n",
    "        lambda_per_sec = effective_rate / 60.0\n",
    "        wait_time = random.expovariate(lambda_per_sec)\n",
    "        time.sleep(wait_time)\n",
    "        event = generate_transaction_event()\n",
    "        producer.produce(\n",
    "            topic,\n",
    "            key=event[\"customer_id\"],\n",
    "            value=json.dumps(event),\n",
    "            callback=delivery_report,\n",
    "        )\n",
    "        producer.poll(0)\n",
    "\n",
    "\n",
    "def flush_topic(broker, topic):\n",
    "    admin_client = AdminClient({\"bootstrap.servers\": broker})\n",
    "    topics = admin_client.list_topics(timeout=10).topics\n",
    "    if topic in topics:\n",
    "        fs = admin_client.delete_topics([topic], operation_timeout=30)\n",
    "        for t, f in fs.items():\n",
    "            try:\n",
    "                f.result()\n",
    "                logging.info(f\"Topic {t} deleted\")\n",
    "            except Exception as e:\n",
    "                logging.error(f\"Deletion failed for topic {t}: {e}\")\n",
    "        time.sleep(10)\n",
    "\n",
    "\n",
    "def topic_has_messages(broker, topic):\n",
    "    conf_cons = {\n",
    "        \"bootstrap.servers\": broker,\n",
    "        \"group.id\": \"dummy\",\n",
    "        \"enable.auto.commit\": False,\n",
    "        \"auto.offset.reset\": \"earliest\",\n",
    "    }\n",
    "    consumer = Consumer(conf_cons)\n",
    "    tp = TopicPartition(topic, 0)\n",
    "    try:\n",
    "        low, high = consumer.get_watermark_offsets(tp)\n",
    "        return high > low\n",
    "    except Exception:\n",
    "        return False\n",
    "    finally:\n",
    "        consumer.close()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    EVENT_RATE = float(os.getenv(\"EVENT_RATE\", 1000))\n",
    "    peak_factor = float(os.getenv(\"PEAK_FACTOR\", 2.5))\n",
    "    fraud_rate = float(os.getenv(\"FRAUD_RATE\", 0.02))\n",
    "    declined_rate = float(os.getenv(\"DECLINED_RATE\", 0.05))\n",
    "    merchant_count = int(os.getenv(\"MERCHANT_COUNT\", 50))\n",
    "    merchant_bases = {\n",
    "        f\"merch_{i}\": {\n",
    "            \"lat\": 35.7219 + random.uniform(-0.1, 0.1),\n",
    "            \"lng\": 51.3347 + random.uniform(-0.1, 0.1),\n",
    "        }\n",
    "        for i in range(1, merchant_count + 1)\n",
    "    }\n",
    "    customer_count = int(os.getenv(\"CUSTOMER_COUNT\", 1000))\n",
    "    kafka_broker = os.getenv(\"KAFKA_BROKER\", \"localhost:9092\")\n",
    "    print(os.getenv(\"KAFKA_BROKER\", \"localhost:9092\"))\n",
    "\n",
    "    topic = \"darooghe.transactions\"\n",
    "    event_init_mode = os.getenv(\"EVENT_INIT_MODE\", \"flush\").lower()\n",
    "    skip_initial = False\n",
    "    if event_init_mode == \"flush\":\n",
    "        flush_topic(kafka_broker, topic)\n",
    "    elif event_init_mode == \"skip\":\n",
    "        if topic_has_messages(kafka_broker, topic):\n",
    "            logging.info(\"Topic has messages; skipping historical events production.\")\n",
    "            skip_initial = True\n",
    "    conf = {\"bootstrap.servers\": kafka_broker}\n",
    "    producer = Producer(conf)\n",
    "    if not skip_initial:\n",
    "        produce_historical_events(producer, topic, count=20000)\n",
    "    logging.info(\"Starting continuous event production...\")\n",
    "    continuous_event_production(producer, topic, base_rate=EVENT_RATE)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DS_CA2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
